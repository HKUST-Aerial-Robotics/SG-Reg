{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SG-Net encoded features for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Room features (from RAM tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "scene_dir = '/data2/ScanNetRag/val/scene0025_00c'\n",
    "with open(scene_dir + '/tags.txt', 'r') as f:\n",
    "    tags = f.readlines()[0]\n",
    "    f.close()\n",
    "\n",
    "    print('The scene has tags: {}'.format(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Object features\n",
    "In SG-Reg, we encode multiple modality of a semantic object:\n",
    "- Local topology feature $\\mathbf{x}$.\n",
    "- Shape feature $\\mathbf{f}$.\n",
    "- Dense point feature $\\mathbf{z}$.\n",
    "\n",
    "<!-- <p align=\"center\">\n",
    "    <img src=\"explicit_sg.png\" width=\"520\"/>\n",
    "</p> -->\n",
    "\n",
    "We encode these features on ScanNet dataset. Please use the following code to load the encoded features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_dict = torch.load(scene_dir + '/features.pth')\n",
    "idxs = feature_dict['instances'] # (N,)\n",
    "x = feature_dict['x'] # (N,d)\n",
    "f = feature_dict['f'] # (N,ds)\n",
    "labels = feature_dict['labels'] # (N,)\n",
    "N = x.shape[0]\n",
    "\n",
    "print('Load {} object features from {}'.format(N, scene_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dense point cloud with instance labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzi = torch.load(scene_dir + '/xyzi.pth') # (P,4)\n",
    "xyzi = xyzi.to(idxs.device)\n",
    "P = xyzi.shape[0]\n",
    "points = xyzi[:,:3] # (P,3)\n",
    "instances = xyzi[:,3].to(torch.int32) # (P,)\n",
    "print('Load {} points from {}'.format(P, scene_dir))\n",
    "print('Check the point cloud of each object:')\n",
    "for i, idx in enumerate(idxs):\n",
    "    masks = instances == idx\n",
    "    print('  object {} ({}) has {} points'.format(idx, labels[i], masks.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a scene (have not tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d \n",
    "from open3d.web_visualizer import draw\n",
    "\n",
    "explicit_scene_folder = '/data2/ScanNetGraph/val/scene0064_00c'\n",
    "\n",
    "instance_map_dir = os.path.join(explicit_scene_folder, '0002.ply')\n",
    "pcd = o3d.io.read_point_cloud(instance_map_dir)\n",
    "print('Load {} points from {}'.format(len(pcd.points), instance_map_dir))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
